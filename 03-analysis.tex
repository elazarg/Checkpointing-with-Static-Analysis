
\begin{figure}[t]
\centering
\[
\renewcommand{\arraystretch}{1.15}
\begin{array}{l@{}ll}
i ::= \;&\hspace{6pt} \$d = \$s & \text{// copy assignment} \\
      &\mid \$d = \tLoadConst(c) & \text{// load constant} \\
      &\mid \$d = \tGetAttr(\$o, k) & \text{// read: } \$d = \$o.k; \text{bind if method} \\
      &\mid \tSetAttr(\$o, k, \$v) & \text{// write: } \$o.k = \$v \\
      &\mid \$d = \mathsf{Call}(\$g) & \text{// invoke potentially-bound call object } \$g() \\
      &\mid \$d = \tLookupDunder(op, \$a)  & \text{// find \_\_\textit{op}\_\_ method to call} \\
      &\mid \$d = \tResolveOverload(\$f, \$a) & \text{// select unique function} \\
      &\mid \$g = \tBind(\$f, \$a) & \text{// build bound call object for } \$f(\$a) \\
      &\mid \tAssumeEq(\$b, \$c) & \text{// continue iff reference-equal} \\
      & \vdots & \vdots \\
      &\mid \tExit & \text{// terminate}
\end{array}
\]
\caption{\spytecode instruction syntax (mnemonic form).}
\label{fig:tac-syntax-reduced}
\end{figure}

\section{Analysis}
\label{sec:analysis}

Our framework is a flow-sensitive abstract interpretation~\cite{cousot1977abstract} that computes invariants at each program point using four cooperating domains: \emph{liveness}, \emph{types}, \emph{pointer}, and \emph{dirty}. 
\emph{Liveness} predicts future variable uses; \emph{types} propagate static type information and function type and effect annotations; \emph{pointer} captures aliasing; and \emph{dirty} tracks heap mutations. Cross-domain exchange is summarized in \Cref{tab:contracts}. We present a simple \emph{stack} domain separately for convenience, though it is part of the pointer domain.
We present components in dependency order: the intermediate representation and its informal semantics; liveness; types; the object and memory model with the stack domain; pointer analysis; and dirty object analysis. \Cref{fig:overview} summarizes the pipeline, from Python source through IR and the cooperating domains, to the invariants used for checkpoint minimization (\Cref{sec:checkpoint-analysis}).

\subsection{Intermediate Representation}
\spyte analyzes Python programs by first converting them to a simplified
register-based \emph{three-address code} intermediate representation called \spytecode. 
Python bytecode is stack-based, which complicates
abstract interpretation by forcing an abstract stack into every domain. A preprocessing
pass converts bytecode to \spytecode,\footnote{This is feasible for compiler-generated Python bytecode with well-formed stack discipline.}
eliminating the operand stack and implicit temporaries in favor of explicit registers
($\$0, \$1, \ldots$). This makes dataflow and heap accesses explicit.
An excerpt of the instructions of \spytecode is shown in \Cref{fig:tac-syntax-reduced}.
%; a more complete definition is included in the appendix.

\paragraph{Control flow.}
A \spytecode program is a nondeterministic control-flow graph with statically known edges.
Branches are represented by conditional assumptions $\tAssumeEq(\$b, \$c)$:
on failure, the path terminates. Both \texttt{return} and uncaught exceptions
are lowered to \tExit, allowing the analysis to reason about all paths
without modeling dynamic exception propagation.

\paragraph{Attribute access.}
$\tSetAttr(\$o, k, \$v)$ writes field $k$ of the object in $\$o$ with the value in $\$v$.
Reading is done with
$\$d = \tGetAttr(\$o, k)$, which is a bit more involved:
(1) if $k$ is present in instance fields of $\$o$, assign that value to $\$d$;
(2) otherwise look up $k$ in the \emph{class}
of $\$o)$; if the result is a function, return
a bound callable with hidden \texttt{self} set to $\$o$, else return the value.
Python's method resolution (MRO) define various rules governing the access of attributes.
\spyte does not model all of them,
but it does support \lstinline|@property|,
modeled as a call to the getter.
When $\$o \in \{\tLOCALS, \tGLOBALS\}$, \tSetAttr/\tGetAttr
correspond to assignment/read of the local/global named variable $k$.

\paragraph{Calls.}
Invocation is factored into distinct steps (arguments are assumed to be packed as a tuple
$\$a$): (a) $\tLookupDunder(op,\$a)$ locates the special method
for operator $op$; (b) $\tResolveOverload(\$f,\$a)$ selects a static target among function overloads (which may be bound or unbound) based on argument classes;\footnote{While Python has no first-class ``overload resolution'' step, it is included in the operational semantics of \spytecode to align better with how type checkers handle overloading. This is vital for the analysis of types and effects, later on.}
(c) \tBind forms an explicit bound call object $\$g$ capturing the callee and its
argument binding; (d) \tCall consumes $\$g$, which must be callable with zero arguments (all arguments are already bound through a special $args$ field), producing the result in $\$d$ and applying the callee's type-annotated effects. This bound object is the anchor for
pointer and effect tracking.

\begin{figure}[t]
    \centering
    \small
    \includesvg[width=\textwidth, inkscapelatex=true]{gfx/analysis-flowchart}
    \caption{Analysis pipeline. Python source is compiled to bytecode, lowered to \spytecode, analyzed in four interacting domains, and finally instrumented.}
    \label{fig:overview}
\end{figure}

In the rest of this section we describe the different analysis domains and their interactions. \Cref{tab:contracts} summarizes what each domain provides.

\subsection{Liveness Analysis}
\label{sec:liveness}

Liveness analysis determines, at each program point, which \spytecode variables may still be used before being overwritten.  
It is a standard backward dataflow pass: moving backwards through the control-flow graph, each instruction adds the variables it reads and removes those it redefines.  Liveness analysis is perfectly sound for compiler-generated stack temporaries, and sound for named locals under our restricted setting (no closures, no use of \texttt{locals()}).

By identifying dead variables, liveness allows the subsequent pointer analysis to prune unreachable heap objects.

With the IR defined and live variables identified, we now turn to the core analysis domains. These track three interrelated aspects of program state: which objects may be dirty (modified since the last checkpoint), how objects point to each other (the heap shape), and what types constrain possible modifications (via effect annotations). The interaction of these domains determines the minimal checkpoint set.

\subsection{Objects and Fields}
We model the heap as a finite set of \emph{abstract objects} $\tO$, where each object represents a potential allocation point in the program. There are four kinds:
\begin{itemize}
    \item \emph{Scopes}: \tLOCALS and \tGLOBALS. Objects representing the local and global variable scope,
respectively.
    \item \emph{Parameter objects} representing the main function's arguments that have been passed from it caller(s). (The callers themselves are not analyzed.)
    \item \emph{Allocation site objects} are summary object representing a set of objects created at specific program locations. 
Locations are addressed by \spytecode instruction index.
    \item Objects of \emph{Immutable types} that do not alias other objects. For example, all integer objects whose value is not precisely known share the same abstract object.
\end{itemize}

An object is modeled using a set of \emph{fields} $\tK$ representing its attributes, dictionary keys, or sequence elements. Since tracking every list index separately would be prohibitive, we use a wildcard symbol $\star$ to represent all indices collectively.

\subsection{Map Domains}
Our type, pointer and dirty analysis domains follow a common pattern: they are maps from keys to values, similar to Python dictionaries but with a default (``bottom'') value for missing keys. This uniformity simplifies both the implementation and the theory.
%%%
A map domain $\tK\to\mathcal{V}$ is constructed from a \emph{key set} $\tK$ and \emph{value lattice} $\mathcal{V}$.
The map domain itself forms a lattice, whose order relation is 
$x\sqsubseteq y \iff \forall k,x[k]\sqsubseteq_{\smlV}y[k]$.
The top and bottom values of the map domain are
$\top=\{k\smlmapstox\top_{\smlV}\mid k\in\tK\}$
and
$\bot=\{k\smlmapstox\bot_{\smlV}\mid k\in\tK\}$.
The \emph{join} ($\sqcup$) and \emph{meet} ($\sqcap$) lattice operators are similarly defined pointwise.

The map-domain layer provides some convenience in the description of abstract semantics.
An instruction typically updates one or more map entries;
%%%
an update can be a \emph{strong update} (denoted $m[k\smlmapsto v']$), meaning that it overwrites the old value,
or a \emph{weak update} (denoted $m\sqcup \{k\smlmapsto v'\}$) that
combines the old and new values conservatively (using $\sqcup_{\smlV}$).

At control-flow join points (where paths merge), we combine information from both branches by taking the union of possibilities. This ensures soundness: \eg, if a field \emph{might} be dirty on \emph{either} path, it is marked dirty after the join. The same map framework works whether we are tracking pointers between objects, dirty fields, or type information; only the range of values in the map changes.

\subsubsection*{Abstract Stack} The abstract stack domain $S$ is a simple map domain, mapping stack indices $\$i$ (``registers'') to the set of objects they may hold:
\[S : \mathds{N} \to \powerset(\tO)\]
%
where $\powerset(\tO)$ is a \emph{power-set lattice} ordered by ${\sqsubseteq}={\subseteq}$ with ${\sqcup}={\cup}$.
The order relation and join operator of $S$ are constructed via the map-domain
directive above.

Operationally, for each instruction the stack domain does two things: first it lifts the stack variables read by the instruction, so that instead of referring to the stack each refers to the objects it might hold. Second, it asks the heap domain for the result of the instruction and stores it in the target stack index (when such a target variable exists). Conceptually this domain can be considered as part of the pointer domain, but we sometimes use it independently.

\begin{table}[t]
\centering
\small
\begin{tabular}{p{15mm}p{20mm}p{33mm}p{42mm}}
\toprule
\textbf{Domain} & \textbf{Abstract State} & \textbf{Observables} & \textbf{Depends on} \\
\midrule
Type ($T$) &
  Object types, modules. &
  Immutability, effects, call and access operations. &
  Reachability (to restrict receivers) \\
\addlinespace
Stack ($S$) & Stack objects
  & Stack root objects & RHS evaluation of IR instructions \\
\addlinespace
Heap ($H$) &
  Pointer graph
  &
  Named variables, field targets, reachability, bound functions &
  Effects, immutability, stack roots \\
\addlinespace
Dirty ($D$) &
  Fields written &
  Dirty fields per object &
  Effects,  immutability, arguments to bound functions \\
\bottomrule
\end{tabular}
\caption{Domain contracts: what each domain exposes and what it requires.}
\label{tab:contracts}
\end{table}

\subsection{Type and Effect Domain}
\label{sec:type}

The type and effect domain tracks the type of each abstract object, maintaining a map \[T : \tO \to (\tK \to \tType)\] 

$\mathsf{Type}$ models Python values using a collection of constructs chosen to match the subset of Python we target: literals, nominal classes, structural protocols, callable signatures, parametric polymorphism with variadic type parameters, and the special \texttt{any} type for unknown values. We omit nominal subtyping since NumPy's API design favors composition and structural subtyping over inheritance hierarchies.

\paragraph{Call checking and binding.}
Function calls are split at the IR level into three or four consecutive steps: (pure) overload resolution, binding of the selected callable to its arguments (allocating a bound callable object), and calling the call object: applying its effect and returning the return value. See \Cref{sec:assumptions} regarding typing subscription of NumPy \texttt{ndarray}s.

\subsubsection{Effects} annotate functions with heap interactions:
\begin{itemize}
  \item \tnew: allocates a fresh object.
  \item \tptstoargs: the \tnew object points to the arguments passed to it. This fits list/set/tuple/dict constructors.
  \item \tboundmeth: informs the pointer domain that the generated value is a bound method with a field \texttt{self} pointing to the receiver object.
  \item \tupdate: modifies or refines a specific field, possibly changing its type. This is very common in methods, such as \lstinline|list.append|, which add points-to references from the object to the argument,
and also may affect the type of the elements in the list,
based on the type of the added element.
\end{itemize}

We rely on library interface files, similar to the type stubs used by existing Python type checkers, that (in addition to types) declare function effects:

\begin{itemize}
  \item Factory functions, such as \texttt{numpy.zeros()} are marked with \tnew, producing a fresh abstract object.
  \item Methods like \lstinline|list.append|, \lstinline|np.array|, \lstinline|np.flatten|, \etc, are annotated with $\tupdate(type, index)$, recording both type refinement of fields and marking arguments dirty in the pointer/dirty domains.
\end{itemize}

\subsection{Pointer Domain}
\label{sec:pointer}

The pointer domain tracks object references from variables
and fields, maintaining two map domains:
%
\[
\begin{array}{@{}l@{}}
  S : \tN \to \powerset(\tO) \\
  H : \tO \to (\tK \to \powerset(\tO))
\end{array}
\]


\begin{figure}[t]
\centering
\begin{minipage}{0.45\textwidth}
\centering
\begin{tikzpicture}[>=stealth,
  node distance=6mm and 8mm,
  every node/.style={inner sep=1pt},
  elabel/.style={midway, fill=white, inner sep=1pt, font=\scriptsize},
  framed/.style={draw,dashed,dash pattern=on 1pt off 2pt, inner sep=3pt}]

% --- BEFORE ---
%\node (headerB) at (-2,3.4) {\footnotesize\textbf{Before}};
\node (localsB) at (0,3.4) {\small \tLOCALS};
\node (loc10B)  [below left =7mm and 8mm of localsB] {\loc{10}};
\node (loc32B)  [below right=7mm and 8mm of localsB] {\loc{32}};
\node (s6B)     [below =5mm of loc10B] {$\$6$};
\node (s5B)     [below =5mm of loc32B] {$\$5$};
\draw[->] (localsB) -- node[elabel,above]{\scriptsize centroids} (loc10B);
\path (localsB) -- node(locXB)[pos=0.6,draw=white,fill,circle,inner sep=1pt] {} (loc32B);
\draw[->] (localsB) -- node[elabel,above,sloped]{\scriptsize X} (locXB);
\draw[->] (locXB) -- node[pos=0.4,elabel,above,sloped]{\scriptsize $\!\star$} (loc32B);
\draw[->] (s6B) -- (loc10B);
\draw[->] (s5B) -- (loc32B);

\node(before)[framed,
  fit=(localsB) (loc10B) (loc32B) (s6B) (s5B)] {};
\node[at=(before.north west), anchor=north west, inner sep=2pt] {\footnotesize\bfseries Before};

% --- IR (center) ---
\node[inner sep=2pt, below=1mm of before,
      align=left] (ir)
{$\begin{array}{@{}r@{\hspace{2mm}}l@{}}
\multicolumn{2}{c}{\mbox{\lstinline|X[sample_i] - centroids|}} \\[1ex]
&\quad \vdots \qquad \vdots \\
\lnn{31} & \$7=\tLookupDunder(\texttt{\_\_sub\_\_},[\$5,\$6]) \\
\lnn{32} & \$7=\tResolveOverload(\$7,[\$5,\$6]) \\
\lnn{33} & \$7=\tBind(\$7,[\$5,\$6])  \\
\lnn{34} & \$5=\tCall(\$7)
\end{array}$};

% --- AFTER ---
\node (localsA) [below= 2mm of ir] {\small \tLOCALS};
%\node (headerA) [left = 1.25cm of localsA] {\footnotesize\textbf{After}};
\node (loc10A)  [below left =7mm and 8mm of localsA] {\loc{10}};
\node (loc32A)  [below right=7mm and 8mm of localsA] {\loc{32}};
\node (loc34A)  [below=7mm of localsA]               {\loc{34}};
\node (s6A)     [below =5mm of loc10A] {$\$6$};
\node (s5A)     [below =5mm of loc34A] {$\$5$};
\draw[->] (localsA) -- node[elabel,above]{\scriptsize centroids} (loc10A);
\path (localsA) -- node(locXA)[pos=0.6,draw=white,fill,circle,inner sep=1pt] {} (loc32A);
\draw[->] (localsA) -- node[elabel,above,sloped]{\scriptsize X} (locXA);
\draw[->] (locXA) -- node[elabel,above,sloped]{\scriptsize $\!\star$} (loc32A);
\draw[->] (s6A) -- (loc10A);
\draw[->] (s5A) -- (loc34A);

\node(after)[framed,
  fit=(localsA) (loc10A) (loc32A) (loc34A) (s5A) (s6A)] {};
\node[at=(after.north west), anchor=north west, inner sep=2pt] {\footnotesize\bfseries After};

\end{tikzpicture}%
\caption{Example update of the pointer domain.}
\label{fig:ptr-example}
\end{minipage}
\hspace{7mm}
%
\begin{minipage}{0.4\textwidth}
\centering
\begin{tikzpicture}[>=stealth,
  every node/.style={inner sep=1pt},
  framed/.style={draw,dashed,dash pattern=on 1pt off 2pt, inner sep=4pt}]

\node(l19) { \loc{19} };
\node(l21)[right=0.5 of l19] { \loc{21} };
\node(l31)[below=0.5 of l19] { \loc{31} };
\node(s4)[left=0.4 of l31] { \$4 };
\node(locals)[left=0.9 of l19, yshift=3mm] { \small \tLOCALS };

\draw[->] (locals) -- node[above,sloped]{\tiny clusters} (l19);
\draw[->] (l19) -- node[above,xshift=-1pt]{\small$\star$} (l21);
\draw[->] (s4) -- (l31);
\draw[->] (l31.north east) -- node[below,sloped]{\tiny self} (l21.south west);

\node(after)[framed,
  fit=(locals) (l19) (l21) (l31) (s4)] {};

\def\blob#1#2{\draw[red,fill=red!40!gray,rounded corners=#1*3mm] (#2) +($(0:#1*2+#1*2*rnd)$)
\foreach \a in {20,30,...,350} {  -- +($(\a: #1*2+#1*2*rnd)$) } -- cycle;}

\node(bb)[at=(l21),xshift=7mm,yshift=5mm] {};
\draw[-{Classical TikZ Rightarrow[length=1mm, 
  width=1.7mm]},green!50!gray,thick]
  (bb) edge[out=180,in=90,looseness=1.7] (l21.45);
\blob{0.05}{bb}


\node(ir)[above=1 of l19]{
$\begin{array}{@{}l@{}}
  \quad \vdots \qquad \vdots \\
  \$4 = \tGetAttr(\$3, \texttt{append}) \\
  \$4 = \tBind(\$4, {\scriptstyle[\ldots]}) \\
  \$3 = \tCall(\$4)
 \end{array}$
};
\node(pycode)[above=0.1 of ir]{
\lstinline|clusters[r].append(sample_i)|
};
\end{tikzpicture}
\caption{Example update of the dirty domain.}
\label{fig:dirty-example}
\end{minipage}
\end{figure}


$S$ is the abstract stack, which was already mentioned above.
$S[i]$ represents a set of objects that may be referenced
by stack variable $\$i$.
$H$ is the abstract heap: $H[o][k]$ is a set of objects that
may be referenced by field $k$ of object $o$.
Recall that, as explained above, each heap object $o\in\tO$
is an abstract \emph{summary object}, which may correspond
to many concrete objects at runtime;
hence, every abstract state $S,H$ represents infinitely
many concrete memory states.
Pointer analysis is a standard technique used in compilers
to determine possible aliasing of pointers, so we do not
delve too much into the abstract semantics of individual
instructions.
This subsection is included for completeness and, especially,
to explain the ways in which pointer analysis interacts with
the other analyses.


\paragraph{Field Operations.}
The semantics of explicit field accesses 
$\tGetAttr(\$o, k)$/$\tSetAttr(\$o, k, \$v)$
involve looking up the set of objects $S[o]$ that may be
referred to by $\$o$.
For \tGetAttr, it generates the abstract value
$\bigsqcup_{p \in S[o]} H[p][k]$.
For \tSetAttr, it updates $H[p]$ for \emph{all} of $p\in S[o]$.
If $S[o]$ is known to address a single concrete object (that is, if it is a singleton set of a singleton object, such as
$\{\tLOCALS\}$),
the semantics would be a strong update
$H[p\smlmapsto \mbox{\small $S[v]$}]$.
Otherwise, it would be a weak update,
$H\sqcup\{p\smlmapsto \mbox{\small $S[v]$}\mid p\in \mbox{\small $S[o]$}\}$.

\tGetAttr/\tSetAttr
Reading field $k$ from objects $O$ returns the union of all possible values. If the object does not have a key, the operation is forwarded to the type system. Writing performs either a \emph{strong update} (replacing the old value) when the target is unique and unaliased, or a \emph{weak update} (accumulating possibilities) otherwise.

For containers with dynamic indexing, the wildcard field $\star$ represents all possible indices. Reading \texttt{obj[i]} consults both the specific index and $\star$; writing updates both to maintain soundness.

\paragraph{Object Allocation.}
New abstract objects arise from three sources:
\begin{itemize}
\item \emph{Explicit allocation} (for example \tBind) creates fresh objects at specific program points
\item \emph{Effect-guided allocation} when the type domain's $\tnew$ effect indicates a method creates objects  
\item \emph{Immutable representatives} for constants, preventing spurious aliasing through shared values
\end{itemize}

\paragraph{Effect Application.}
Method calls apply effects from the type domain:
\begin{itemize}
\item \tnew: Allocate a fresh object at the call site (instruction location). Objects sharing allocation site are merged together.
\item \tptstoargs: Wire edges from result to arguments (e.g., the set constructor \texttt{\{a,b\}})
\item $\tupdate(T, arg)$: Modify argument receiver to point to the argument $arg$, changing its type to $T$, coordinating with dirty tracking and types. Updates annotated with $*arg$ instead means updating to point to the same elements pointed to by $arg$. 
\item \tboundmeth: Track method-to-receiver binding for indirect calls
\end{itemize}

\begin{example}
%
Consider the assignment statement in \Cref{fig:ptr-example}.
The operation being performed is subtraction;
the \spytecode snippet relevant for calling the
subtraction routine is shown in the middle.
Stack variable $\$7$ is populated with a bound 
function object corresponding to the method (\lstinline|__sub__|).
The pointer domain takes from the type information that this method has the effect \tnew.
The semantics of this effect is to allocate a fresh object \loc{34} corresponding to the call site, and update the stack to $S[\$5\smlmapsto\loc{34}]$, accordingly.
The heap $H$ is unchanged, since the type of the bound method at $\$7$ (\loc{33}) carries no \tupdate effect.
\end{example}


The domain traces through bound method objects to find actual receivers, enabling precise tracking even when methods are stored in variables.

\subsection{Dirty Domain}
The \emph{dirty} domain maps each object to the set of fields written since the last checkpoint:
\[D : \tO \to \powerset(\tK)\]

An update marks the corresponding field as dirty; deletions are treated as writes. 
Tracking fields is needed specifically for the \tLOCALS and \tGLOBALS objects, to identify which local/global variables have been directly assigned to.
For other objects, field sensitivity is not crucial (our implementation ignores it),
but we describe it uniformly for presentation purposes.

\begin{example}
Consider the assignment statement in \Cref{fig:dirty-example},
occurring in the inner loop of \Cref{lst:code-kmeans}.
\end{example}

%
In \spytecode, the call to \lstinline|append| is embodied
in the instruction $\$3 = \tCall(\$4)$.
Prior to the $\tCall$, a bound-function object (\loc{31}) is
constructed via $\tGetAttr$/$\tBind$ instructions, with a field
\lstinline|self| referring to the receiver object (\loc{21}).
%Assume the dirty state (just before $\tCall$) of:
%$D = \big\{\tLOCALS\smlmapsto\{\textrm{clusters}\}, 
%      (\loc{31})\smlmapsto\top\big\}$.

In order to update $D$, the dirty analysis needs information from the pointer~\Cref{sec:pointer} and type~\Cref{sec:type} domains.
From the pointer domain, it needs to know about the path $\$4\to\loc{31} \to \loc{21}$
as shown in the figure;
From the type domain, it needs to know the \emph{effects}
associated with the type of $\loc{31}$.
The type of $\loc{31}$ corresponds to \texttt{list.append},
which has the \tupdate effect.
Based on that information, the abstract semantics of
$\tCall(\$4)$ is $\lambda D.~D\sqcup\{\loc{21}\smlmapsto\top\}$ (the key \loc{21} is taken from the pointer path, and $\top$ is based on the \tupdate
effect).

\subsection{Domain Interactions}
The domains refine each other with directed information flow:
\begin{itemize}
    \item \emph{Liveness $\rightarrow$ Pointer:} prunes unreachable roots and their edges.
    \item \emph{Type $\rightarrow$ Pointer:} constrains possible targets based on typed effect annotations.
    \item \emph{Type $\rightarrow$ Dirty:} immutable objects never become dirty.
    \item \emph{Pointer $\rightarrow$ Type:} dynamic dispatch resolution is narrowed to types of reachable receivers.
    \item \emph{Pointer $\rightarrow$ Dirty:} arguments of bound functions for which \tupdate is performed.
\end{itemize}
These interactions improve precision by removing impossible states before they can pollute other domains.

\subsection{Assumptions}
\label{sec:assumptions}
The soundness of our analysis relies on targeting a disciplined subset of Python, prohibiting dynamic code evaluation, and requiring that function calls be statically resolvable modulo overload resolution. Furthermore, we assume correctness of user-provided type and side-effect annotations.
%\Cref{sec:appendix-assumptions} lists our assumptions in more detail.

In handling numerical libraries, we make several simplifying trade-offs for tractability. The analysis does not model mutation through NumPy's view-based aliasing. Our type system is also dimensionality-agnostic (as is common among type checkers), which simplifies analysis but cannot distinguish between scalar and array values returned from slicing operations without additional user hints.

\section{Checkpointing Analysis and Instrumentation}
\label{sec:checkpoint-analysis}

The final stage combines information from all domains to compute, at each loop head, the least sufficient set (w.r.t.\ our abstraction) of locals that must be persisted so that execution can resume correctly after a crash.

\subsection{Checkpoint Set Computation}

Let $\ell$ be a loop head. We use the abstract state at each back-edge (end of the body; it is trivial to find since we analyze \lstinline{For} loops that have dedicated instructions) that targets $\ell$.
Let $\tK$ denote the global field-key alphabet (attribute names, dictionary keys, indices, \emph{etc.}).
Let $\mathcal{N}\subseteq\tK$ be the subset used by $\tLOCALS$ (i.e., local variable names), and write $\text{Live}(\ell)\subseteq\mathcal{N}$ for the set of live local names at entry to $\ell$.
Given $H$ as the heap component of the pointer domain, and $D$ the field-sensitive dirty map.

\paragraph{Definition (Checkpoint Set).}
The checkpoint set $C_\ell\subseteq\mathcal{N}$ is:
\[
v\in C_\ell \iff v\in \text{Live}(\ell)\ \wedge\
\Big( v\in D[\tLOCALS] \ \ \lor\ \ \exists o\in \text{Reach}\big(H[\tLOCALS][v],\,H\big).\ D[o]\neq\varnothing \Big).
\]
Here $\text{Reach}(R,H)$ is the transitive closure of objects reachable from root set $R$ along $H$.
Intuitively: we persist a live local if it was assigned during the iteration, or if its value may reach a modified heap object. We do not persist local variables that are not live.

\paragraph{Soundness (sketch).}
At a crash boundary placed on every back-edge to $\ell$, persisting bindings for $C_\ell$ yields, upon recovery at $\ell$, an environment whose live locals equal the pre-crash ones:
(i) rebinds are captured by $v\in D[\tLOCALS]$; (ii) heap mutations are captured because any live root whose reachable region contains a dirty object is persisted with its reachable subgraph, and serialization is graph-preserving (aliasing and cycles retained); (iii) domains over-approximate behavior, so no necessary local is omitted. External effects are excluded or modeled by typed effect annotations.

\paragraph{Precision.}
Liveness prunes dead locals; type/effect information prevents marking provably update-free objects as dirty; field sensitivity on $\tLOCALS$ distinguishes individual variable rebinds. Over-approximation can enlarge $C_\ell$, but never breaks correctness.

\subsection{Code Transformation}

We assume a prior normalization that gives each loop head a well-defined set of back-edges (all \texttt{continue} sites included) and reifies loop control when needed.

\paragraph{Checkpoint insertion.}
We serialize the loop-control state together with locals in $C_\ell$. For the K-Means example with $C_\text{outer} = \{\texttt{centroids}\}$:
\begin{lstlisting}[language=Python]
if checkpoint.exists():
    [centroids] = checkpoint.restore()
for i in checkpoint.iterate(range(max_iterations)):
    # loop body unchanged ...
    centroids = new_centroids
    checkpoint.commit(centroids)  # checkpoint at back-edge
\end{lstlisting}

The \texttt{checkpoint} abstraction handles loop-control persistence and restoration transparently. Graph-preserving serialization maintains aliasing and cycles. Parameter objects are treated as heap roots and are persisted only if reachable from some $v\in C_\ell$. Atomicity is ensured through write-to-temp and rename (or journaling), providing all-or-nothing visibility.

\begin{figure}[t]
\centering

\begin{tikzpicture}[
  box/.style={rectangle, rounded corners=3pt, draw,
              inner xsep=3mm, inner ysep=2mm, align=left},
  obox/.style={box,text width=15mm},
  env/.style={ellipse, draw,
              inner xsep=4mm, inner ysep=1.5mm, align=center},
  edge/.style={-Stealth},
  elabel/.style={sloped, midway, fill=white, inner sep=1pt, font=\footnotesize},
  ty/.style={font=\footnotesize, inner sep=1pt}
]

% Locals environment
\node[box] (locals) {\tLOCALS};

% Heap objects
\matrix (M) [matrix of nodes,
             nodes=obox,
             row sep=4mm,
             column sep=18mm,
             right=20mm of locals, yshift=-1.2cm] {
  \node (loc19) [label={[ty]below:list[list[int]]}]
    {\loc{19}}; &
  \node (loc21) [label={[ty]below:list[int]}]
    {\loc{21}}; \\
  \node (paramX) [label={[ty]below:ndarray}] {\param{X}}; & \\
  \node (loc40) [label={[ty]below:ndarray}]
    {\loc{40}}; & \\
  \node (loc22)[label={[ty]below:Iterator[int]}]  
    {\loc{22}}; & \\
};

\node(s1)[left=of loc22] { \$1 };

% Edges
\draw[edge] (s1) -- (loc22);
\draw[edge] (locals) -- (loc19) node[elabel,above] {clusters};
\draw[edge] (loc19) -- (loc21) node[elabel,above] {$\star$};
\draw[edge] (locals) -- (paramX) node[elabel,above] {X};
\draw[edge] (locals) -- (loc40) node[elabel,above] {centroids};

\node[right=of paramX,anchor=north west,scale=0.9]{
\renewcommand\arraystretch{1.2}
\begin{tabular}{l}
\textbf{Liveness (at loop entry)} \\
  $\{\texttt{X},\ \texttt{centroids},\ \texttt{k}\}$
 \\[2ex]
\textbf{Dirty (at back-edge)} \\
 $D[\tLOCALS] = \{\texttt{clusters},\texttt{centroids}\}$ \\
 $D[\loc{19}] = \top$ \\
\end{tabular}
};

\end{tikzpicture}
\caption{Invariants obtained from the analysis of the main loop of K-Means.}
\label{fig:example-invariants}
\end{figure}

\begin{example}
In the K-Means first outer loop, the invariant of the combined domains is depicted in \Cref{fig:example-invariants}.

By the definition of \(C_\ell\), liveness at the head prunes both \texttt{clusters} and the loop index name:
even though \(\texttt{clusters}\) reaches a dirty object (\(\loc{179}\)) inside the body, it is not live at \(\ell\).
Conversely, \texttt{centroids} is live and is in \(D[\tLOCALS]\) at the back-edge, so it must be persisted.
Therefore \(C_{\text{outer}}=\{\texttt{centroids}\}\).
\end{example}

This least-sufficient checkpoint under our abstraction—a single variable rather than the full program state—drives the savings quantified in \Cref{sec:evaluation}.
