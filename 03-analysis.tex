
\begin{figure}[t]
\centering
\[
\renewcommand{\arraystretch}{1.15}
\begin{array}{l@{}ll}
i ::= \;&\hspace{6pt} \$d = \$s & \text{// copy assignment} \\
      &\mid \$d = \mathsf{Const}(c) & \text{// load constant} \\
      &\mid \$d = \mathsf{GetAttr}(\$o, k) & \text{// read: } \$d = \$o.k; \text{bind if method} \\
      &\mid \mathsf{SetAttr}(\$o, k, \$v) & \text{// write: } \$o.k = \$v \\
      &\mid \$d = \mathsf{Call}(\$g) & \text{// invoke potentially-bound call object } \$g() \\
      &\mid \$d = \mathsf{LookupDunder}(op, \$a)  & \text{// find \_\_\textit{op}\_\_ method to call\si{op what}} \\
      &\mid \$d = \mathsf{ResolveOverload}(\$f, \$a) & \text{// select unique function} \\
      &\mid \$g = \mathsf{Bind}(\$f, \$a) & \text{// build bound call object for } \$f(\$a) \\
      &\mid \mathsf{AssumeEq}(\$b, \$c) & \text{// continue iff reference-equal} \\
      & \vdots & \vdots \\
      &\mid \mathsf{Exit} & \text{// terminate}
\end{array}
\]
\caption{\spytecode instruction syntax (mnemonic form).}
\label{fig:tac-syntax-reduced}
\end{figure}

\section{Analysis}
\label{sec:analysis}

Our framework is a flow-sensitive abstract interpretation~\cite{cousot1977abstract} that computes invariants at each program point using four cooperating domains: \emph{liveness}, \emph{dirty}, \emph{pointer}, and \emph{types}. \emph{Liveness} predicts future variable uses; \emph{dirty} tracks heap mutations; \emph{pointer} captures aliasing; and \emph{types} propagate static type information and function type and effect annotations. Cross-domain exchange is summarized in~\autoref{tab:contracts}. We present components in dependency order: the intermediate representation and its informal semantics; liveness; the object and memory model; and the specialized domains. \autoref{fig:overview} summarizes the pipeline, from Python source and IR, through the cooperating domains, to the invariants used for checkpoint minimization.

\subsection{Intermediate Representation}
\spyte analyzes Python programs by first converting them to a simplified
register-based \emph{three-address code} intermediate representation called \spytecode. 
Python bytecode is stack-based, which complicates
abstract interpretation by forcing an abstract stack into every domain. A preprocessing
pass converts bytecode to \spytecode,\footnote{This is feasible for compiler-generated Python bytecode with well-formed stack discipline.}
eliminating the operand stack and implicit temporaries in favor of explicit registers
($\$0, \$1, \ldots$). This makes dataflow and heap accesses explicit.
An excerpt of the instructions of \spytecode is shown in \autoref{fig:tac-syntax-reduced}; a more complete
definition is included in the appendix.

\paragraph{Control flow.}
A \spytecode program is a nondeterministic control-flow graph with statically known edges.
Branches are represented by conditional assumptions \textsf{AssumeEq}$(\$b, \$c)$:
on failure, the path terminates. Both \texttt{return} and uncaught exceptions
are lowered to \textsf{Exit}, allowing the analysis to reason about all paths
without modeling dynamic exception propagation.

\paragraph{Attribute access.}
\textsf{SetAttr}$(\$o, k, \$v)$ writes field $k$ of the object in $\$o$ with the value in $\$v$.
\textsf{GetAttr}$(\$d, \$o, k)$ resolves $k$ on $\$o$:
(1) if present in instance fields, assign that value to $\$d$;
(2) otherwise look up $k$ in $\mathrm{class}(\$o)$; if the result is a function, return
a bound callable with hidden \texttt{self} set to $\$o$, else return the value.
We do not model Python's full MRO or the general descriptor protocol; the sole
exception is \texttt{property}, modeled by immediately invoking its; this case make the instruction effectful.
When $\$o \in \{\tLOCALS, \tGLOBALS\}$, \tSetAttr/\tGetAttr
correspond to assignment/read of the named variable $k$.

\paragraph{Calls.}
Invocation is factored into distinct steps (arguments are assumed to be packed as a tuple
$\$a$): (a) \textsf{LookupDunder}$(op,\$a)$ locates the special method
for operator $op$; (b) \textsf{ResolveOverload}$(\$f,\$a)$ selects a static target among function overloads (which may be bound or unbound) based on argument classes;\footnote{While CPython has no first-class ``overload resolution'' step, it is included in the operational semantics of \spytecode to align better with how type checkers handle overloading. This is vital for the analysis of types and effects, later on.}
(c) \textsf{Bind} forms an explicit bound call object $\$g$ capturing the callee and its
argument binding; (d) \textsf{Call} consumes $\$g$, which must be callable with zero arguments (all arguments are already bound through a special $args$ field), producing the result in $\$d$ and applying the callee's type-annotated effects. This bound object is the anchor for
pointer and effect tracking.

\begin{figure}[t]
    \centering
    \includesvg[width=\textwidth, inkscapelatex=false]{gfx/analysis-flowchart}
    \caption{Analysis pipeline. Python source is compiled to bytecode, lowered to \spytecode, and analyzed in three interacting domains, and finally instrumented.}
    \label{fig:overview}
\end{figure}

In the rest of this section we describe the different analysis domains and their interactions. \autoref{tab:contracts} summarize what each domain provides.

\subsection{Liveness Analysis}
\label{sec:liveness}
Liveness analysis determines, at each program point, which \spytecode variables may still be used before being overwritten.  
It is a standard backward dataflow pass: moving backwards through the control-flow graph, each instruction adds the variables it reads and removes those it redefines.  Liveness analysis is perfectly sound for compiler-generated stack temporaries, and sound for named locals under our restricted setting (no closures, no use of \texttt{locals()}).

By identifying dead variables, liveness allows the subsequent pointer analysis to prune unreachable heap objects.

With the IR defined and live variables identified, we now turn to the core analysis domains. These track three interrelated aspects of program state: which objects may be dirty (modified since the last checkpoint), how objects point to each other (the heap shape), and what types constrain possible modifications (via effect annotations). The interaction of these domains determines the minimal checkpoint set.

\subsection{Objects and Fields}
We model the heap as a finite set of \emph{abstract objects} $\mathcal{O}$, where each object represents a potential allocation point in the program. There are four kinds:
\begin{itemize}
    \item \emph{Scope}: \tLOCALS and \tGLOBALS. Those are accessed only using their corresponding instructions.
    \item \emph{Parameter objects} representing function arguments passed from callers.
    \item \emph{Allocation site objects} created at specific program locations. If line 5 creates a list, all lists created there share one abstract object..
    \item Objects of \emph{Immutable types} that do not alias other objects. For example, all integer objects whose value is not precisely known share the same abstract object.
\end{itemize}
Each object has \emph{fields} $\mathcal{F}$ representing its attributes, dictionary keys, or sequence elements. Since tracking every list index separately would be prohibitive, we use a wildcard field $\star$ to represent all indices collectively.

\subsection{Map Domains}
Our type, pointer and dirty analysis domains follow a common pattern: they are maps from keys to values, similar to Python dictionaries but with a default value for missing keys. This uniformity simplifies both the implementation and the theory.
When an instruction updates a map entry, we face a choice. If we know exactly which key is being written (no aliasing), we can perform a \emph{strong update} that replaces the old value. But if multiple keys might be affected, we must perform a \emph{weak update} that combines the old and new values conservatively. For example, if \texttt{x} might point to one of two objects, then \texttt{x.f = 5} must weakly update both objects' fields.

At control-flow join points (where paths merge), we combine information from both branches by taking the union of possibilities. This ensures soundness: if a field might be dirty on either path, it's marked dirty after the join. The same map framework works whether we're tracking pointers between objects, dirty fields, or type information; only the type of values in the map changes.

\begin{table}[t]
\centering
\small
\begin{tabular}{p{15mm}p{36mm}p{37mm}p{40mm}}
\toprule
\textbf{Domain} & \textbf{Abstract State} & \textbf{Observables (to others)} & \textbf{Depends on} \\
\midrule
Type ($T$) &
  $T:\mathcal O\to \mathcal \mathcal{T}$
  Type of object, global modules. &
  Immutability, effects, call and access operations. &
  Pointer reachability to restrict receivers; library stubs. \\
\addlinespace
Pointer ($P$) &
  $P:\mathcal O\to(\mathcal F\to \mathcal P(\mathcal O))$.
  Pointer graph.&
  (i) Field targets $P[o][f]$; (ii) reachability $Reach(R,P)$. &
  Roots, Effects, immutability. \\
\addlinespace
Dirty ($D$) &
  $D:\mathcal O\to \mathcal P(\mathcal F)$ (fields written). &
  Set of dirty fields per object. &
  Effects,  immutability. \\
\bottomrule
\end{tabular}
\caption{Domain contracts: what each domain exposes and what it requires.}
\label{tab:contracts}
\end{table}

\subsection{Type and Effect Domain}
Our type domain models Python values using a set of constructs chosen to match the subset of Python we target: literals, nominal classes, structural protocols, callable signatures, parametric polymorphism with variadic type parameters, and the special \texttt{any} type for unknown values. We do not model nominal subtyping (superclasses), since we've found no need to do so in our domain.

\paragraph{Call checking and binding.}
Calls are split at the IR level into three or four consecutive steps: (pure) overload resolution, binding of the selected callable to its arguments (allocating a bound callable object), and calling the call object: applying its effect and returning the return value.~\footnote{Caveat: like most contemporary type analyses, we do not track dimensionality of numpy's ndarrays (but see \cite{liu2020type}). Unfortunately, this means the analysis cannot distinguish between subscriptions that return an float and subscriptions and subscriptions that return a slice of an ndarray. We therefore use simple \texttt{get\_float()} helpers for the former --- a form of type annotations required from the programmer.}

\subsubsection{Effects} annotate functions with heap interactions:
\begin{itemize}
  \item \textbf{\texttt{new}}: allocates a fresh object.
  \item \textbf{\texttt{points\_to\_args}}: the \texttt{new} objects points to the arguments passed to it. This fits list/set/tuple/dict constructors.
  \item \textbf{\texttt{bound\_method}} tells the pointer domain the method points from \texttt{self} to the argument.
  \item \textbf{\texttt{update}}: modifies or refines a specific field, possibly changing its type. This is very common in methods, and it tells the dirty domain to count the relevant arguments as dirty. Note: Type-changing updates are only applied when the receiver is unaliased and monomorphic, preventing unsound refinements across aliases. The analysis aborts when this is not the case.
\end{itemize}

We rely on library interface files, similar in spirit to the type stubs used by existing Python type checkers, that declare function effects:

\begin{itemize}
  \item Factory functions, such as \texttt{numpy.zeros()} are marked with \textbf{\texttt{new}}, producing a fresh abstract object.
  \item Methods like \texttt{list.append} are annotated with \textbf{\texttt{update(type, index)}}, recording both type refinement of fields and marking arguments dirty in the pointer/dirty domains.
\end{itemize}

\subsection{Dirty Domain}
The \emph{dirty} domain maps each object to the set of fields written since the last checkpoint.
An update marks the corresponding field as dirty; deletions are treated as writes.
The domain itself does not decide which dirty objects must be checkpointed; this decision is deferred until pointer reachability and liveness are taken into account.

\subsection{Pointer Domain}
The \emph{pointer domain} models the shape of the heap as a map
\[
P : \mathcal{O} \to (\mathcal{F} \to \mathcal{P}(\mathcal{O}))
\]
where $P[o][f]$ is the set of abstract objects that may be stored in field $f$ of object $o$.
The inner map has default value $\emptyset$ for any field not explicitly present.


\begin{figure}[t]
\centering

\begin{tikzpicture}[
  box/.style={rectangle, rounded corners=3pt, draw, thick, fill=blue!8,
              text width=15mm, inner xsep=3mm, inner ysep=2mm, align=left},
  env/.style={ellipse, draw, thick, fill=blue!8,
              inner xsep=4mm, inner ysep=1.5mm, align=center},
  edge/.style={-Stealth, thick},
  elabel/.style={sloped, midway, fill=white, inner sep=1pt, font=\footnotesize}
]

% Stack environment
\node[env] (stack) {S};

% Locals environment
\node[box, below=18mm of stack] (locals) {LOCALS};

% Heap objects
\matrix (M) [matrix of nodes,
             nodes=box,
             row sep=7mm,
             column sep=18mm,
             right=20mm of locals] {
  \node (loc22)  {\texttt{Loc 22}\\\footnotesize Iterator[int]}; & \\[-1mm]
  \node (loc179) {\texttt{Loc 179}\\\footnotesize list[list[int]]}; &
  \node (loc212) {\texttt{Loc 212}\\\footnotesize list[int]}; \\[-1mm]
  \node (paramX) {\texttt{param X}\\\footnotesize ndarray}; & \\[-1mm]
  \node (loc540) {\texttt{Loc 540}\\\footnotesize ndarray}; & \\
};

% Edges
\draw[edge] (stack) -- (loc22) node[elabel,above] {$\$1$};
\draw[edge] (locals) -- (loc179) node[elabel,above] {clusters};
\draw[edge] (loc179) -- (loc212) node[elabel,above] {\texttt{*}};
\draw[edge] (locals) -- (paramX) node[elabel,above] {X};
\draw[edge] (locals) -- (loc540) node[elabel,above] {centroids};

\end{tikzpicture}
\caption{Points-to graph of the k-means code at the end of the loop body}
\label{fig:objgraph}
\end{figure}

\paragraph{Transfer.}
On an instruction that stores a reference into a field --- for example \texttt{x.f = y} --- we first resolve the set of possible source objects $S$ for $y$ and the set of possible target objects $T$ for $x$.
For each $t \in T$, we update $P[t][f]$ with $S$.
If $t$ is known to be the only object bound to $x$ (no aliasing), we perform a \emph{strong update}:
\[
P[t][f] \leftarrow S.
\]
If aliasing is possible, we perform a \emph{weak update}:
\[
P[t][f] \leftarrow P[t][f] \cup S.
\]
Reads, such as \texttt{y = x.f}, do not change $P$ but are resolved by looking up $\bigcup_{t \in T} P[t][f]$.

\paragraph{Join and Subsumption.}
The join $P_1 \sqcup P_2$ is computed pointwise over objects and fields, taking the union of target sets.
Subsumption $P_1 \sqsubseteq P_2$ holds if $P_1[o][f] \subseteq P_2[o][f]$ for all $o \in \mathcal{O}$ and $f \in \mathcal{F}$.

\paragraph{Reachability.}
Given a set of \emph{root objects} $R \subseteq \mathcal{O}$ (live fields of \texttt{LOCALS}), the set of \emph{reachable objects} $\mathsf{Reach}(R, P)$ is the smallest set containing $R$ and closed under:
\[
o \in \mathsf{Reach}(R, P) \wedge o' \in P[o][f] \implies o' \in \mathsf{Reach}(R, P).
\]
We use liveness to prune the roots $R$ before reachability is computed, ensuring that dead variables do not keep their objects alive.

\paragraph{Field and attribute access.}
For $x.f$, the pointer domain yields possible receivers; their rows are inspected:
\begin{itemize}
  \item If all agree on the field type, that type is returned.
  \item If types disagree, their join is returned.
  \item If the field is missing, join with the residual row's default (often \texttt{any}) and mark as possibly failing.
\end{itemize}

% \paragraph{Example: partial application and update.}
% Consider:
% \[
% f : \forall T,U.\; (0:T, 1:U) \to T
% \]
% Calling $f$ with an \texttt{int} yields a residual $(0:U) \to \texttt{int}$.  
% Calling this residual with a \texttt{str} then yields a residual  $() \to \texttt{int}$; finally, retrieving the result yields an \texttt{int}.  
% Similarly, \texttt{list.append} with an \texttt{int} argument refines the element type from unknown to \texttt{int}.

% \paragraph{Precision and limits.}
% The type system can:
% \begin{enumerate}
%   \item Identify an overapproximation of the set of heap locations an operation may modify.
%   \item Exclude immutable structures from checkpoints.
%   \item Refine container element types across updates.
% \end{enumerate}
% Precision loss occurs when joins force widening to \texttt{any} (e.g., differing field types, many unknowns, or unknown attribute names).  
% Dynamic features such as monkey--patching, dynamic imports, or metaclass manipulation are excluded from the target subset.

\subsection{Domain Interactions}
The domains refine each other with directed information flow:
\begin{itemize}
    \item \emph{Liveness $\rightarrow$ Pointer:} prunes unreachable roots and their edges.
    \item \emph{Type $\rightarrow$ Pointer:} constrains possible targets based on typed effect annotations.
    \item \emph{Type $\rightarrow$ Dirty:} immutable objects never become dirty.
    \item \emph{Pointer $\rightarrow$ Type:} dynamic dispatch resolution is narrowed to types of reachable receivers.
\end{itemize}
These interactions improve precision by removing impossible states before they can pollute other domains.

\subsection{Transfer Functions}
For each instruction, the transfer function updates only the affected keys in each domain according to the instruction's semantics.
Weak updates are applied when aliasing is possible, and joins are used when merging control-flow paths.
The set of checkpoint roots at loop boundaries is obtained by intersecting live roots with reachable dirty objects.
