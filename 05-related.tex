\section{Related Work}
\label{sec:related}

\subsection{Static Analysis of Dynamically-Typed Languages}
Static analysis of dynamically typed languages presents a unique challenge due to their lack of explicit type annotations, dynamic object structures, and runtime features such as \texttt{eval} and dynamic attribute creation. A significant body of research has addressed these challenges, with approaches ranging from type inference and alias analysis to abstract interpretation over rich semantic domains.

\paragraph{Type and Pointer Analysis in Python.}
Early efforts at type analysis for Python include Starkiller~\cite{salib2004starkiller}, a whole-program ahead-of-time compiler performing interprocedural type inference. Starkiller demonstrated the feasibility of static compilation for a large subset of Python by modeling control-flow and using a variant of the Cartesian Product Algorithm. RPython~\cite{ancona2007rpython} took a more restrictive route, defining a statically analyzable subset of Python suitable for ahead-of-time translation, forming the basis of the PyPy project.

Subsequent work focused on formalizing type analysis through abstract interpretation. Fritz and Hage~\cite{fritz2017cost} evaluated configurable approximate typing for Python, showing that flow-insensitive treatment of module-scope variables improves both speed and precision, while call-site sensitivity adds cost with little precision benefit.
More recently, Fromherz et al.~\cite{fromherz2018static} and Monat et al.~\cite{monat2021static}~\cite{monat2021multilanguage} developed abstract interpreters over custom domains capable of analyzing control-flow-sensitive types and values, including object-oriented features, exceptions, and generators. The latter system, \textbf{Mopsa}, models both nominal and structural typing, deals with C extensions, and tracks container shapes and type equality relationships. In its pointer analysis, Mopsa uses \emph{recency abstraction}, keeping the most recent pointer value in addition to the combined value for other iterations, which enhances precision. We've found no need for this abstraction in the programs we analyzed. 

Beyond specific analyses, Li et al.\ introduced Scalpel~\cite{li2022scalpel}, a general-purpose static analysis framework for Python.

Aliasing in Python---analogous to pointer analysis---has also been studied. Gorbovitski et al.~\cite{gorbovitski2010alias} proposed a flow- and context-sensitive alias analysis for Python, enabling optimizations like memoization.

\paragraph{Practical Tools for Python.}
Gradual type checkers such as Mypy~\cite{mypy}, Pyre~\cite{pyre}, and Pytype~\cite{pytype} are widely used in practice. While unsound by design, they use flow-sensitive and partially context-sensitive type inference to catch common bugs and enable scalable static typing. Pytype notably employs abstract interpretation internally, treating variables and control-flow through a form of symbolic execution over types and heap aliases. These tools sacrifice soundness for usability, offering fast feedback and integration with developer workflows.

\paragraph{Abstract Interpretation in Other Dynamic Languages.}
The use of abstract interpretation is well-established in the analysis of other dynamic languages. For JavaScript, TAJS~\cite{jensen2009type} and JSAI~\cite{kashyap2014jsai} applied abstract interpretation to model ECMAScript features such as prototype inheritance and dynamic property creation. JSAI's design incorporates a reduced product of domains for type, pointer, numeric, and string analysis. These frameworks support sound over-approximations of JavaScript semantics and demonstrate high configurability and modularity.

In Ruby, the DRuby system~\cite{furr2009static} introduced a sophisticated type language with union and intersection types, modeling Ruby's dynamic method dispatch. RDL and InferDL~\cite{kazerounian2020sound} extend this work by inferring and refining types using heuristics and partial static analysis. SimTyper~\cite{kazerounian2021simtyper} proposes sound type inference for Ruby by combining constraint-based inference with machine learning-based type equality prediction. Using a neural similarity model (DeepSim), SimTyper refines overly general types to more usable ones, matching programmer-written annotations while preserving soundness.

Lua also saw the introduction of Typed Lua~\cite{maidl2014typed}, which defines a gradual type system with union types and subtyping. Practical variants like Luau (Roblox) and Teal build on these ideas to enable static checking in large-scale Lua applications.

\paragraph{Static Analysis for Compilation and Specialization.}
A major motivation for static analysis of dynamic languages has historically been ahead-of-time compilation and runtime specialization. Starkiller~\cite{salib2004starkiller} targeted static compilation, while RPython~\cite{ancona2007rpython} defines a restricted, analyzable subset of Python enabling C code generation and tracing JITs in PyPy. In JavaScript, systems like TAJS~\cite{jensen2009type} and JSAI~\cite{kashyap2014jsai} support aggressive optimization and specialization. Related strategies have been adopted in Ruby and Lua to enable efficient execution or compilation. Even in more static languages like Julia, type inference underpins aggressive method specialization and inlining. Across these efforts, the analysis result is consumed to produce faster code --- either at compile time or as part of a just-in-time execution strategy.

\paragraph{Static Analysis for Program Transformation.}
Beyond compilation, static analysis has occasionally been used to guide automated transformations for purposes other than performance. Gorbovitski et al.~\cite{gorbovitski2010alias} use alias analysis in Python to enable automatic memoization of function calls. In JavaScript, abstract interpretation has been used to generate instrumentation for profiling and taint tracking. These works exemplify a broader but less explored class of applications in which analysis drives transformation, modifying the program or its runtime behavior based on inferred properties. Our work falls into this category, but targets a distinct goal: using type and pointer information to automatically manage and prune checkpoints in Python programs. To our knowledge, this is the first application of static analysis for dynamic languages aimed at improving recoverability through transformation of the program’s state management.

\subsection{Static Analysis-Based Checkpointing}

Static analysis has long been used to optimize checkpointing by identifying which portions of program state are necessary for correct recovery. Early work such as CATCH by Li and Fuchs~\cite{li1990catch} demonstrated the feasibility of using compiler-based liveness analysis and memory classification to exclude dead or recomputable data from checkpoints in Fortran and C programs. While foundational, this work was limited to relatively rigid memory models.

Rodríguez et al.~\cite{rodriguez2010cppc} developed CPPC, a source-to-source compiler for MPI applications that applies interprocedural data-flow analysis to automatically insert variable-level checkpoints. The static analysis component is essential in abstracting over low-level, non-portable state and allowing transparent instrumentation, particularly in distributed environments.

Vogt et al.~\cite{vogt2015lightweight} extend LLVM to support high-frequency user-level checkpointing via byte-level memory instrumentation. While their work focuses on runtime performance, it crucially relies on LLVM's data structure analysis (a context- and field-sensitive points-to analysis) to identify non-escaping memory objects --- a form of checkpoint escape analysis --- which are then excluded from instrumentation. This use of static pointer analysis improves performance by reducing unnecessary state tracking, particularly for stack and transient heap data.

Kim et al.~\cite{kim2024lact} apply array-level liveness analysis to reduce checkpoint overhead in intermittent computing environments. Their approach statically analyzes memory access patterns across loop structures to determine which portions of arrays are no longer live at checkpoint sites. This static pruning substantially reduces energy and storage costs in sensor workloads where large arrays dominate memory usage.

De Kruijf et al.~\cite{de2012static} propose \textit{idempotent processing}, a compiler-based technique that partitions programs into statically identified re-executable regions. These regions are guaranteed to produce the same results on re-execution, allowing recovery without checkpointing. Their work uses control- and data-flow analysis to identify safe region boundaries and optimize speculative execution without requiring hardware rollback.
