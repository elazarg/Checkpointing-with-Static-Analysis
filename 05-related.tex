\section{Related Work}
\label{sec:related}

\paragraph{From feasibility to structural analyzability.}
Early efforts showed that static reasoning about Python is possible: Starkiller performed whole-program type inference~\cite{salib2004starkiller}, RPython and PyPy defined analyzable sublanguages for ahead-of-time compilation~\cite{ancona2007rpython}, and Gorbovitski et al. demonstrated practical alias analysis~\cite{gorbovitski2010alias}. These ambitious systems were early signs of what later became a trend. The turning point came with gradual typing~\cite{siek2007gradual,vitousek2014design}: tools like Mypy, Pytype, and Pyre brought type annotations into production Python~\cite{mypy,pytype,pyre}. Building on this foundation, abstract interpretation frameworks now track values and effects across modules, including native C extensions~\cite{fromherz2018static,monat2021static,monat2021multilanguage}, while practical call-graph construction handles dynamic features at scale~\cite{salis2021pycg,rakamnouykit2024potohybridandersenspointsto}. Empirical studies confirm that type annotations improve analyzability in practice~\cite{bence2021unambiguity}. Dynamic ecosystems beyond Python show the same evolution, for example JavaScript and Ruby~\cite{jensen2009type,furr2009static,kashyap2014jsai,kazerounian2021simtyper}. Together, these developments reflect a broader shift: Python usage increasingly favors disciplined, analyzable patterns, making automated transformations practical.

\paragraph{Compiler-guided, application-level checkpointing.}
Compiler assistance for checkpointing has a clear lineage. CATCH saved only state proven live across restart and reduced overhead substantially~\cite{li1990catch}. Application-level frameworks in HPC, including C3 and CPPC, instrumented programs to persist the variables identified by compile-time data flow rather than snapshotting whole processes~\cite{bronevetsky2004application,rodriguez2010cppc}. Later work refined this idea in new settings: structure-aware schemes for loop and array codes, storage-aware optimizations that leverage non-volatile memory, and compiler-directed incremental checkpointing for preemption~\cite{elnawawy2017efficient,kannan2013optimizing,ji2022compiler}. Recent results push liveness down to array regions in intermittent systems, excluding dead elements and reducing writes at compile time~\cite{kim2024lact}. System-level tools such as DMTCP and CRIU, including in-memory CRIU and VM-delta methods, remain process- or VM-wide by design~\cite{AnselAryaCooperman2009DMTCP,CRIUProject,venkatesh2019fast,MoshikSOCC22}.

\paragraph{Convergence in Python.}
These trajectories meet in scientific and numerical Python, where workloads increasingly exhibit analyzable patterns: type annotations, predictable control flow, and stable libraries~\cite{bence2021unambiguity,PEP484}. Our work exploits this convergence, showing that compiler techniques for reliability --- not just performance --- can extend to dynamic languages.
