\section{Introduction}
Python powers much of modern numerical computing through libraries like NumPy and SciPy. The language's dynamic features, such as dynamic typing, reflection, and flexible control flow, make static analysis notoriously difficult. Yet many Python programs deliberately avoid these constructs, favoring typed, consistent code and stable libraries. For such well-structured code, we show that established static analysis techniques can be usefully adapted to specific domains of interest. We focus on one important problem domain: efficient checkpointing of long-running programs. 
In this work we demonstrate leveraging static analysis information to perform lightweight program instrumentation, reducing storage writes by orders of magnitude compared to existing checkpointing approaches.

Checkpointing is the task of capturing the program state at designated points to enable recovery of work done in case of failure. Unexpected faults in long-running or resource-intensive computations can lead to costly recomputation and lost work. Traditional checkpointing is typically implemented at the system level, treating applications as black boxes. Tools such as CRIU~\cite{corbet2011checkpoint} snapshot an entire Linux process, including memory, file descriptors, and registers. Virtual machine snapshots~\cite{VMwareSnapshot, RedHatVMSnapshot} go further, capturing the entire guest operating system state. While robust and language-agnostic, this approach is usually highly inefficient as it demands large amounts of data be written to storage---even when the checkpoint is done incrementally, and even when deduplicated~\cite{meyer2012study} and compressed~\cite{ferreira2013checkpoint}---
because modern software uses volatile memory extensively, 
taking advantage of ever-growing fast RAM hardware.

Application-level checkpointing offers an alternative: preserving only the program state that influences future computation. A naive approach might be capturing all reachable state from within the scope of the current program location. Capturing all reachable state is overly conservative. Much of the state is immutable or transient and not needed after resumption.  This naive approach might result in even worse performance than checkpointing the entire process incrementally.

Prior work has shown that analysis-assisted checkpointing can shrink state substantially by saving only data that remain live across a restart. This idea dates back to CATCH~\cite{li1990catch} and to application-level frameworks in high-performance computing such as C3 ~\cite{bronevetsky2004application} and CPPC~\cite{rodriguez2010cppc}, which use program analysis to identify variables that will be read after a checkpoint and to instrument code accordingly. Recent work revives this direction, computing liveness over array slices to exclude dead values and reduce writes~\cite{kim2024lact}. To our knowledge, comparable liveness-based minimization has not been attempted for fully dynamic languages like Python; dynamic typing, closures, reflection, and mutable object layouts complicate sound, precise liveness and pointer analysis.

That said, many Python workloads already operate within a restricted, well-structured subset of the language~\cite{bence2021unambiguity}. They avoid reflection, rely on type annotations, follow predictable control flow, and depend on stable libraries with well-understood semantics. While these practices limit some of Python's flexibility, they are common in scientific computing, where correctness and performance outweigh dynamic features. Use of this subset of language features defines the class of programs our static analysis targets.

Our framework, \spyte, combines liveness, pointer, and type analyses with lightweight effect annotations. These annotations classify operations in built-in types and external libraries as allocating, mutating, or pure, enabling analysis of third-party code while maintaining useful precision in heap-shape tracking. Similarly to compiler optimizations, we adopt a \emph{happy-path} approach: assuming the program is correct and inputs are valid, in order to focus precision on the intended execution path.

Building on this framework, we introduce an analysis that identifies the subset of local variables that must be persisted to ensure correct recovery. The analysis finds heap objects that get modified and are reused across loop iterations, tracks which variables point to these objects (directly or indirectly), and selects only those variables as essential state to preserve for recovery. We instrument the code to checkpoint these variables after each iteration and restore them at recovery time. This includes saving state at iteration boundaries and loading it at loop entry, with special handling for the loop iterator.

We evaluate the approach on realistic implementations of numerical algorithms: K-Means clustering~\cite{macqueen1967multivariate}, Orthogonal Matching Pursuit (OMP)~\cite{Pati1993OMP}, and clique enumeration (pivoter)~\cite{jain2020power}. These case studies confirm that static analysis techniques, carefully applied to structurally disciplined Python code, can yield major practical benefits.

Our work is complementary to Numba~\cite{numba2015}, which accelerates Python's numeric code by specializing types, propagating shapes/strides, and fusing/parallelizing array kernels. While Numba optimizes execution, it does not maintain a persistent heap/alias model. In contrast, we perform points-to analysis using library-agnostic effect annotations to preserve the heap structure needed to identify and restore the minimal state after a restart. Numba's results motivate our premise that scientific Python is analyzable; \spyte supplies the missing heap-aware, effect-generic layer for checkpointing.

\subsubsection*{Contributions}
\begin{samepage}
\begin{enumerate}
\item A reusable static analysis framework for well-typed, structured Python code satisfying certain structural assumptions.
\item Specialized analysis and synthesis steps for checkpoint I/O minimization via \emph{minimal persistent root set} analysis.
\item An empirical demonstration showing that semantically guided checkpointing is feasible and highly effective in practical, albeit constrained, Python workloads.
\end{enumerate}
\end{samepage}

The remainder of the paper is organized as follows. In \Cref{sec:running-example} we present a running example based on the K-Means clustering algorithm to illustrate the challenges and opportunities for selective checkpointing in numerical Python code. \Cref{sec:analysis} describes our analysis framework in detail, including the intermediate representation, the design of the type and pointer domains, and the interaction between liveness, type, heap and dirty analyses. \Cref{sec:checkpoint-analysis} presents our specialized analysis for identifying variables to checkpoint and the instrumentation process. \Cref{sec:evaluation} evaluates our approach on several realistic workloads, comparing our synthesized checkpoints against naive and system-level baselines. \Cref{sec:related} discusses related work in static analysis for dynamic languages and checkpointing. We conclude in \Cref{sec:conclusion} with a summary of our contributions and directions for future work.
